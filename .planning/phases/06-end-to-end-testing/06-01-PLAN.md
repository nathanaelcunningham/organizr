---
phase: 06-end-to-end-testing
plan: 01
type: execute
---

<objective>
Verify the complete audiobook automation workflow from torrent submission through organized files with both unit-level coverage and integration testing.

Purpose: Validate that all components work together correctly - qBittorrent integration, download monitoring, file organization, and frontend updates - ensuring production readiness.
Output: Comprehensive test coverage (80%+ on critical paths), documented manual test scenarios, and verified end-to-end workflow from download creation to organized files.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
./summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-frontend-integration/05-01-SUMMARY.md
@.planning/phases/04-file-organization-engine/04-01-SUMMARY.md
@.planning/phases/02-download-monitoring/02-01-SUMMARY.md
@backend/internal/downloads/monitor.go
@backend/internal/downloads/organization.go
@backend/internal/downloads/organization_test.go
@backend/internal/qbittorrent/client.go
@backend/internal/server/handlers.go
@frontend/src/stores/useDownloadStore.ts
@frontend/src/stores/useDownloadStore.test.ts

**Tech stack available:**
- Backend: Go with stdlib testing, table-driven test patterns, t.TempDir() for isolation
- Frontend: Vitest with testing-library/react (22 existing tests in useDownloadStore)
- Database: SQLite with repository pattern
- Integration: qBittorrent client, monitoring service, organization service

**Established patterns:**
- Interface-based testing with mock implementations
- Table-driven tests for comprehensive coverage
- Temporary directories for file operations testing
- Deferred panic recovery with cleanup

**Constraining decisions:**
- Phase 2: 3-second polling interval, auto-organization on completion
- Phase 4: All-or-nothing copy, partial move recovery, 10% disk space buffer
- Phase 5: Vitest for frontend testing, auto-organization toggle defaults to enabled

**Current state:**
- Backend tests: organization_test.go (70% coverage), template_test.go
- Frontend tests: useDownloadStore.test.ts (22 tests, comprehensive store coverage)
- Missing: API handler tests, monitor tests, qBittorrent client tests
- Missing: Integration tests for full workflow
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add comprehensive backend handler tests</name>
  <files>backend/internal/server/handlers_test.go</files>
  <action>
    Create test file for HTTP handlers covering:

    **CreateDownload handler:**
    - Test valid magnet link creates download and returns 201
    - Test valid torrent file (.torrent) creates download
    - Test MAM URLs trigger torrent file download (mock HTTP)
    - Test invalid URL returns 400
    - Test qBittorrent failure returns 500
    - Test category parameter is passed through

    **GetDownloads handler:**
    - Test returns all downloads with 200
    - Test pagination (if implemented)
    - Test filters by status (if implemented)

    **OrganizeDownload handler:**
    - Test triggers organization for completed download
    - Test returns 400 for non-existent download
    - Test returns 400 for non-completed download

    **CancelDownload handler:**
    - Test removes download and returns 204
    - Test returns 404 for non-existent download

    **TestQBittorrentConnection handler:**
    - Test returns success when qBittorrent reachable
    - Test returns error details when qBittorrent unreachable

    Use httptest.NewRecorder() for response testing. Mock downloadService and configService. Use table-driven tests for different scenarios.

    IMPORTANT: Focus on HTTP layer (status codes, request/response handling). Business logic is tested in service layer. Mock all service dependencies.
  </action>
  <verify>go test -v ./backend/internal/server passes with >80% coverage on handlers.go</verify>
  <done>All handlers covered with tests for success, error, and edge cases. HTTP layer verified independently from business logic.</done>
</task>

<task type="auto">
  <name>Task 2: Add monitor service tests</name>
  <files>backend/internal/downloads/monitor_test.go</files>
  <action>
    Create test file for download monitor covering:

    **Monitor lifecycle:**
    - Test Start() launches monitoring goroutine
    - Test Stop() gracefully shuts down monitor
    - Test concurrent Start() calls are safe

    **Download tracking:**
    - Test addDownload() adds to tracking map
    - Test removeDownload() removes from tracking
    - Test multiple downloads tracked simultaneously

    **Status updates:**
    - Test monitor detects progress changes (0% → 50% → 100%)
    - Test monitor detects status changes (downloading → completed)
    - Test state transition logging (only logs on change, not every poll)

    **Auto-organization:**
    - Test auto-organization triggers when download completes and config enabled
    - Test auto-organization skipped when config disabled
    - Test organization errors are handled gracefully

    **Resilience:**
    - Test monitor continues when qBittorrent temporarily unavailable
    - Test warnings logged but monitoring doesn't stop

    **Context handling:**
    - Test monitor respects context cancellation
    - Test organization goroutines use parent context with timeout

    Use mock qBittorrent client, mock config service, mock organization service. Test with channels for synchronization (avoid time.Sleep for flaky tests). Use t.TempDir() for any file operations.

    IMPORTANT: These are complex concurrency tests. Use proper synchronization (channels, sync.WaitGroup) to avoid race conditions. Run with `go test -race` to verify.
  </action>
  <verify>go test -v -race ./backend/internal/downloads passes, monitor_test.go covers >70% of monitor.go logic</verify>
  <done>Monitor lifecycle, download tracking, status updates, auto-organization, and resilience all tested with proper concurrency handling</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>Comprehensive test coverage across backend (handlers + monitor + organization) and frontend (store)</what-built>
  <how-to-verify>
    1. Run backend tests: `cd backend && go test -v -race -cover ./...`
    2. Check coverage report - expect >70% on critical paths (handlers, monitor, organization)
    3. Run frontend tests: `cd frontend && npm test`
    4. Verify all 22+ tests pass (including new handler/monitor tests)
    5. Check for race conditions - `go test -race` should show no warnings
    6. Review test output for any skipped or flaky tests
  </how-to-verify>
  <resume-signal>Type "approved" if all tests pass with good coverage, or describe issues to fix</resume-signal>
</task>

<task type="auto">
  <name>Task 3: Create manual E2E test documentation</name>
  <files>.planning/phases/06-end-to-end-testing/E2E-TEST-SCENARIOS.md</files>
  <action>
    Create comprehensive manual testing guide documenting the full workflow with specific test scenarios:

    **Prerequisites section:**
    - qBittorrent running and configured (Web UI enabled, credentials set)
    - Backend running (`cd backend && go run cmd/api/main.go`)
    - Frontend running (`cd frontend && npm run dev`)
    - Test destination folder created and writable

    **Scenario 1: Happy path - Magnet link download**
    1. Navigate to frontend
    2. Paste magnet link into download form
    3. Expected: Download appears in list with "queued" status
    4. Expected: Status transitions to "downloading" within 10 seconds
    5. Expected: Progress bar updates during download
    6. Expected: Status changes to "completed" when done
    7. Expected: Auto-organization triggers (status → "organizing")
    8. Expected: Files appear in destination with correct folder structure
    9. Expected: Status changes to "organized" with organized_path displayed
    10. Verify: Click "Copy Path" button, verify clipboard contains correct path

    **Scenario 2: MAM torrent file download**
    1. Paste MAM torrent URL (https://www.myanonamouse.net/tor/download.php?tid=XXX)
    2. Expected: Backend downloads .torrent file before submitting to qBittorrent
    3. Expected: Download proceeds normally through organized status

    **Scenario 3: Manual organization (auto-org disabled)**
    1. Disable auto-organization in config
    2. Add download
    3. Expected: Download stops at "completed" (no auto-organize)
    4. Click "Organize Now" button
    5. Expected: Organization proceeds, status → organized

    **Scenario 4: Organization retry after failure**
    1. Configure invalid destination path (permissions error)
    2. Add download, wait for completion
    3. Expected: Organization fails, error displayed
    4. Fix destination path in config
    5. Click "Retry Organization" button
    6. Expected: Organization succeeds

    **Scenario 5: Download cancellation**
    1. Add download
    2. While downloading, click "Cancel" button
    3. Expected: Download removed from list
    4. Verify: qBittorrent no longer shows torrent

    **Scenario 6: Connection testing**
    1. Click "Test Connection" button on config page
    2. Expected: Success message if qBittorrent reachable
    3. Stop qBittorrent
    4. Click "Test Connection" again
    5. Expected: Error message with details

    **Scenario 7: Polling behavior**
    1. Add multiple downloads
    2. Expected: Status updates every 3 seconds while downloads active
    3. Wait for all downloads to complete and organize
    4. Expected: Polling stops automatically (no active downloads)
    5. Add new download
    6. Expected: Polling resumes automatically

    **Acceptance criteria:**
    - All 7 scenarios documented with step-by-step instructions
    - Expected behaviors clearly stated
    - Common failure modes and troubleshooting included
    - Screenshots or example outputs provided where helpful

    This document serves as the QA checklist before production deployment.
  </action>
  <verify>E2E-TEST-SCENARIOS.md exists with all 7 scenarios documented, clear steps and expected behaviors</verify>
  <done>Manual testing guide complete, ready for QA execution and production validation</done>
</task>

</tasks>

<verification>
Before declaring phase complete:
- [ ] `go test -v -race -cover ./backend/...` passes with >70% coverage on handlers, monitor, organization
- [ ] `cd frontend && npm test` passes all tests (22+ including new tests)
- [ ] No race conditions detected by `go test -race`
- [ ] E2E-TEST-SCENARIOS.md exists with 7 documented scenarios
- [ ] All tests run cleanly without flaky failures
</verification>

<success_criteria>

- Backend handler tests cover all HTTP endpoints (CreateDownload, GetDownloads, OrganizeDownload, CancelDownload, TestQBittorrentConnection)
- Monitor tests cover lifecycle, tracking, status updates, auto-organization, resilience, and context handling
- Combined backend test coverage >70% on critical paths
- Frontend tests continue to pass (22+ tests)
- No race conditions in concurrent code
- Manual E2E test scenarios documented with 7 comprehensive workflows
- Phase 6 complete - project ready for production deployment
</success_criteria>

<output>
After completion, create `.planning/phases/06-end-to-end-testing/06-01-SUMMARY.md`:

# Phase 6 Plan 1: End-to-End Testing and Production Readiness Summary

**[Substantive one-liner - what was tested and verified]**

## Accomplishments

- [Key testing achievements]
- [Coverage improvements]
- [E2E scenarios documented]

## Files Created/Modified

- `backend/internal/server/handlers_test.go` - HTTP handler test coverage
- `backend/internal/downloads/monitor_test.go` - Monitor service concurrency tests
- `.planning/phases/06-end-to-end-testing/E2E-TEST-SCENARIOS.md` - Manual QA guide

## Decisions Made

[Testing strategy decisions and rationale, or "None"]

## Issues Encountered

[Problems during testing and resolutions, or "None"]

## Next Phase Readiness

Phase 6 complete. All phases (1, 1.1, 2, 3, 4, 5, 6) finished. Project is production-ready with comprehensive test coverage and documented QA procedures. Ready for deployment and real-world usage.
</output>
